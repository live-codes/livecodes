{
  "version": 3,
  "sources": ["../../../../../node_modules/@codemirror/legacy-modes/mode/coffeescript.js"],
  "sourcesContent": ["var ERRORCLASS = \"error\";\n\nfunction wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar operators = /^(?:->|=>|\\+[+=]?|-[\\-=]?|\\*[\\*=]?|\\/[\\/=]?|[=!]=|<[><]?=?|>>?=?|%=?|&=?|\\|=?|\\^=?|\\~|!|\\?|(or|and|\\|\\||&&|\\?)=)/;\nvar delimiters = /^(?:[()\\[\\]{},:`=;]|\\.\\.?\\.?)/;\nvar identifiers = /^[_A-Za-z$][_A-Za-z$0-9]*/;\nvar atProp = /^@[_A-Za-z$][_A-Za-z$0-9]*/;\n\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\",\n                                \"is\", \"isnt\", \"in\",\n                                \"instanceof\", \"typeof\"]);\nvar indentKeywords = [\"for\", \"while\", \"loop\", \"if\", \"unless\", \"else\",\n                      \"switch\", \"try\", \"catch\", \"finally\", \"class\"];\nvar commonKeywords = [\"break\", \"by\", \"continue\", \"debugger\", \"delete\",\n                      \"do\", \"in\", \"of\", \"new\", \"return\", \"then\",\n                      \"this\", \"@\", \"throw\", \"when\", \"until\", \"extends\"];\n\nvar keywords = wordRegexp(indentKeywords.concat(commonKeywords));\n\nindentKeywords = wordRegexp(indentKeywords);\n\n\nvar stringPrefixes = /^('{3}|\\\"{3}|['\\\"])/;\nvar regexPrefixes = /^(\\/{3}|\\/)/;\nvar commonConstants = [\"Infinity\", \"NaN\", \"undefined\", \"null\", \"true\", \"false\", \"on\", \"off\", \"yes\", \"no\"];\nvar constants = wordRegexp(commonConstants);\n\n// Tokenizers\nfunction tokenBase(stream, state) {\n  // Handle scope changes\n  if (stream.sol()) {\n    if (state.scope.align === null) state.scope.align = false;\n    var scopeOffset = state.scope.offset;\n    if (stream.eatSpace()) {\n      var lineOffset = stream.indentation();\n      if (lineOffset > scopeOffset && state.scope.type == \"coffee\") {\n        return \"indent\";\n      } else if (lineOffset < scopeOffset) {\n        return \"dedent\";\n      }\n      return null;\n    } else {\n      if (scopeOffset > 0) {\n        dedent(stream, state);\n      }\n    }\n  }\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  var ch = stream.peek();\n\n  // Handle docco title comment (single line)\n  if (stream.match(\"####\")) {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle multi line comments\n  if (stream.match(\"###\")) {\n    state.tokenize = longComment;\n    return state.tokenize(stream, state);\n  }\n\n  // Single line comment\n  if (ch === \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle number literals\n  if (stream.match(/^-?[0-9\\.]/, false)) {\n    var floatLiteral = false;\n    // Floats\n    if (stream.match(/^-?\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\d+\\.\\d*/)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\.\\d+/)) {\n      floatLiteral = true;\n    }\n\n    if (floatLiteral) {\n      // prevent from getting extra . on 1..\n      if (stream.peek() == \".\"){\n        stream.backUp(1);\n      }\n      return \"number\";\n    }\n    // Integers\n    var intLiteral = false;\n    // Hex\n    if (stream.match(/^-?0x[0-9a-f]+/i)) {\n      intLiteral = true;\n    }\n    // Decimal\n    if (stream.match(/^-?[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n      intLiteral = true;\n    }\n    // Zero by itself with no other piece of number.\n    if (stream.match(/^-?0(?![\\dx])/i)) {\n      intLiteral = true;\n    }\n    if (intLiteral) {\n      return \"number\";\n    }\n  }\n\n  // Handle strings\n  if (stream.match(stringPrefixes)) {\n    state.tokenize = tokenFactory(stream.current(), false, \"string\");\n    return state.tokenize(stream, state);\n  }\n  // Handle regex literals\n  if (stream.match(regexPrefixes)) {\n    if (stream.current() != \"/\" || stream.match(/^.*\\//, false)) { // prevent highlight of division\n      state.tokenize = tokenFactory(stream.current(), true, \"string.special\");\n      return state.tokenize(stream, state);\n    } else {\n      stream.backUp(1);\n    }\n  }\n\n\n\n  // Handle operators and delimiters\n  if (stream.match(operators) || stream.match(wordOperators)) {\n    return \"operator\";\n  }\n  if (stream.match(delimiters)) {\n    return \"punctuation\";\n  }\n\n  if (stream.match(constants)) {\n    return \"atom\";\n  }\n\n  if (stream.match(atProp) || state.prop && stream.match(identifiers)) {\n    return \"property\";\n  }\n\n  if (stream.match(keywords)) {\n    return \"keyword\";\n  }\n\n  if (stream.match(identifiers)) {\n    return \"variable\";\n  }\n\n  // Handle non-detected items\n  stream.next();\n  return ERRORCLASS;\n}\n\nfunction tokenFactory(delimiter, singleline, outclass) {\n  return function(stream, state) {\n    while (!stream.eol()) {\n      stream.eatWhile(/[^'\"\\/\\\\]/);\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n        if (singleline && stream.eol()) {\n          return outclass;\n        }\n      } else if (stream.match(delimiter)) {\n        state.tokenize = tokenBase;\n        return outclass;\n      } else {\n        stream.eat(/['\"\\/]/);\n      }\n    }\n    if (singleline) {\n      state.tokenize = tokenBase;\n    }\n    return outclass;\n  };\n}\n\nfunction longComment(stream, state) {\n  while (!stream.eol()) {\n    stream.eatWhile(/[^#]/);\n    if (stream.match(\"###\")) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    stream.eatWhile(\"#\");\n  }\n  return \"comment\";\n}\n\nfunction indent(stream, state, type = \"coffee\") {\n  var offset = 0, align = false, alignOffset = null;\n  for (var scope = state.scope; scope; scope = scope.prev) {\n    if (scope.type === \"coffee\" || scope.type == \"}\") {\n      offset = scope.offset + stream.indentUnit;\n      break;\n    }\n  }\n  if (type !== \"coffee\") {\n    align = null;\n    alignOffset = stream.column() + stream.current().length;\n  } else if (state.scope.align) {\n    state.scope.align = false;\n  }\n  state.scope = {\n    offset: offset,\n    type: type,\n    prev: state.scope,\n    align: align,\n    alignOffset: alignOffset\n  };\n}\n\nfunction dedent(stream, state) {\n  if (!state.scope.prev) return;\n  if (state.scope.type === \"coffee\") {\n    var _indent = stream.indentation();\n    var matched = false;\n    for (var scope = state.scope; scope; scope = scope.prev) {\n      if (_indent === scope.offset) {\n        matched = true;\n        break;\n      }\n    }\n    if (!matched) {\n      return true;\n    }\n    while (state.scope.prev && state.scope.offset !== _indent) {\n      state.scope = state.scope.prev;\n    }\n    return false;\n  } else {\n    state.scope = state.scope.prev;\n    return false;\n  }\n}\n\nfunction tokenLexer(stream, state) {\n  var style = state.tokenize(stream, state);\n  var current = stream.current();\n\n  // Handle scope changes.\n  if (current === \"return\") {\n    state.dedent = true;\n  }\n  if (((current === \"->\" || current === \"=>\") && stream.eol())\n      || style === \"indent\") {\n    indent(stream, state);\n  }\n  var delimiter_index = \"[({\".indexOf(current);\n  if (delimiter_index !== -1) {\n    indent(stream, state, \"])}\".slice(delimiter_index, delimiter_index+1));\n  }\n  if (indentKeywords.exec(current)){\n    indent(stream, state);\n  }\n  if (current == \"then\"){\n    dedent(stream, state);\n  }\n\n\n  if (style === \"dedent\") {\n    if (dedent(stream, state)) {\n      return ERRORCLASS;\n    }\n  }\n  delimiter_index = \"])}\".indexOf(current);\n  if (delimiter_index !== -1) {\n    while (state.scope.type == \"coffee\" && state.scope.prev)\n      state.scope = state.scope.prev;\n    if (state.scope.type == current)\n      state.scope = state.scope.prev;\n  }\n  if (state.dedent && stream.eol()) {\n    if (state.scope.type == \"coffee\" && state.scope.prev)\n      state.scope = state.scope.prev;\n    state.dedent = false;\n  }\n\n  return style == \"indent\" || style == \"dedent\" ? null : style;\n}\n\nexport const coffeeScript = {\n  name: \"coffeescript\",\n  startState: function() {\n    return {\n      tokenize: tokenBase,\n      scope: {offset: 0, type:\"coffee\", prev: null, align: false},\n      prop: false,\n      dedent: 0\n    };\n  },\n\n  token: function(stream, state) {\n    var fillAlign = state.scope.align === null && state.scope;\n    if (fillAlign && stream.sol()) fillAlign.align = false;\n\n    var style = tokenLexer(stream, state);\n    if (style && style != \"comment\") {\n      if (fillAlign) fillAlign.align = true;\n      state.prop = style == \"punctuation\" && stream.current() == \".\"\n    }\n\n    return style;\n  },\n\n  indent: function(state, text) {\n    if (state.tokenize != tokenBase) return 0;\n    var scope = state.scope;\n    var closer = text && \"])}\".indexOf(text.charAt(0)) > -1;\n    if (closer) while (scope.type == \"coffee\" && scope.prev) scope = scope.prev;\n    var closes = closer && scope.type === text.charAt(0);\n    if (scope.align)\n      return scope.alignOffset - (closes ? 1 : 0);\n    else\n      return (closes ? scope.prev : scope).offset;\n  },\n\n  languageData: {\n    commentTokens: {line: \"#\"}\n  }\n};\n"],
  "mappings": "AAAA,IAAIA,EAAa,QAEjB,SAASC,EAAWC,EAAO,CACzB,OAAO,IAAI,OAAO,MAAQA,EAAM,KAAK,KAAK,EAAI,OAAO,CACvD,CAEA,IAAIC,EAAY,mHACZC,EAAa,gCACbC,EAAc,4BACdC,EAAS,6BAETC,EAAgBN,EAAW,CAAC,MAAO,KAAM,MACb,KAAM,OAAQ,KACd,aAAc,QAAQ,CAAC,EACnDO,EAAiB,CAAC,MAAO,QAAS,OAAQ,KAAM,SAAU,OACxC,SAAU,MAAO,QAAS,UAAW,OAAO,EAC9DC,EAAiB,CAAC,QAAS,KAAM,WAAY,WAAY,SACvC,KAAM,KAAM,KAAM,MAAO,SAAU,OACnC,OAAQ,IAAK,QAAS,OAAQ,QAAS,SAAS,EAElEC,EAAWT,EAAWO,EAAe,OAAOC,CAAc,CAAC,EAE/DD,EAAiBP,EAAWO,CAAc,EAG1C,IAAIG,EAAiB,sBACjBC,EAAgB,cAChBC,EAAkB,CAAC,WAAY,MAAO,YAAa,OAAQ,OAAQ,QAAS,KAAM,MAAO,MAAO,IAAI,EACpGC,EAAYb,EAAWY,CAAe,EAG1C,SAASE,EAAUC,EAAQC,EAAO,CAEhC,GAAID,EAAO,IAAI,EAAG,CACZC,EAAM,MAAM,QAAU,OAAMA,EAAM,MAAM,MAAQ,IACpD,IAAIC,EAAcD,EAAM,MAAM,OAC9B,GAAID,EAAO,SAAS,EAAG,CACrB,IAAIG,EAAaH,EAAO,YAAY,EACpC,OAAIG,EAAaD,GAAeD,EAAM,MAAM,MAAQ,SAC3C,SACEE,EAAaD,EACf,SAEF,IACT,MACMA,EAAc,GAChBE,EAAOJ,EAAQC,CAAK,CAG1B,CACA,GAAID,EAAO,SAAS,EAClB,OAAO,KAGT,IAAIK,EAAKL,EAAO,KAAK,EAGrB,GAAIA,EAAO,MAAM,MAAM,EACrB,OAAAA,EAAO,UAAU,EACV,UAIT,GAAIA,EAAO,MAAM,KAAK,EACpB,OAAAC,EAAM,SAAWK,EACVL,EAAM,SAASD,EAAQC,CAAK,EAIrC,GAAII,IAAO,IACT,OAAAL,EAAO,UAAU,EACV,UAIT,GAAIA,EAAO,MAAM,aAAc,EAAK,EAAG,CACrC,IAAIO,EAAe,GAYnB,GAVIP,EAAO,MAAM,4BAA4B,IAC3CO,EAAe,IAEbP,EAAO,MAAM,aAAa,IAC5BO,EAAe,IAEbP,EAAO,MAAM,UAAU,IACzBO,EAAe,IAGbA,EAEF,OAAIP,EAAO,KAAK,GAAK,KACnBA,EAAO,OAAO,CAAC,EAEV,SAGT,IAAIQ,EAAa,GAajB,GAXIR,EAAO,MAAM,iBAAiB,IAChCQ,EAAa,IAGXR,EAAO,MAAM,2BAA2B,IAC1CQ,EAAa,IAGXR,EAAO,MAAM,gBAAgB,IAC/BQ,EAAa,IAEXA,EACF,MAAO,QAEX,CAGA,GAAIR,EAAO,MAAML,CAAc,EAC7B,OAAAM,EAAM,SAAWQ,EAAaT,EAAO,QAAQ,EAAG,GAAO,QAAQ,EACxDC,EAAM,SAASD,EAAQC,CAAK,EAGrC,GAAID,EAAO,MAAMJ,CAAa,EAAG,CAC/B,GAAII,EAAO,QAAQ,GAAK,KAAOA,EAAO,MAAM,QAAS,EAAK,EACxD,OAAAC,EAAM,SAAWQ,EAAaT,EAAO,QAAQ,EAAG,GAAM,gBAAgB,EAC/DC,EAAM,SAASD,EAAQC,CAAK,EAEnCD,EAAO,OAAO,CAAC,CAEnB,CAKA,OAAIA,EAAO,MAAMb,CAAS,GAAKa,EAAO,MAAMT,CAAa,EAChD,WAELS,EAAO,MAAMZ,CAAU,EAClB,cAGLY,EAAO,MAAMF,CAAS,EACjB,OAGLE,EAAO,MAAMV,CAAM,GAAKW,EAAM,MAAQD,EAAO,MAAMX,CAAW,EACzD,WAGLW,EAAO,MAAMN,CAAQ,EAChB,UAGLM,EAAO,MAAMX,CAAW,EACnB,YAITW,EAAO,KAAK,EACLhB,EACT,CAEA,SAASyB,EAAaC,EAAWC,EAAYC,EAAU,CACrD,OAAO,SAASZ,EAAQC,EAAO,CAC7B,KAAO,CAACD,EAAO,IAAI,GAEjB,GADAA,EAAO,SAAS,WAAW,EACvBA,EAAO,IAAI,IAAI,GAEjB,GADAA,EAAO,KAAK,EACRW,GAAcX,EAAO,IAAI,EAC3B,OAAOY,MAEJ,IAAIZ,EAAO,MAAMU,CAAS,EAC/B,OAAAT,EAAM,SAAWF,EACVa,EAEPZ,EAAO,IAAI,QAAQ,EAGvB,OAAIW,IACFV,EAAM,SAAWF,GAEZa,CACT,CACF,CAEA,SAASN,EAAYN,EAAQC,EAAO,CAClC,KAAO,CAACD,EAAO,IAAI,GAAG,CAEpB,GADAA,EAAO,SAAS,MAAM,EAClBA,EAAO,MAAM,KAAK,EAAG,CACvBC,EAAM,SAAWF,EACjB,KACF,CACAC,EAAO,SAAS,GAAG,CACrB,CACA,MAAO,SACT,CAEA,SAASa,EAAOb,EAAQC,EAAOa,EAAO,SAAU,CAE9C,QADIC,EAAS,EAAGC,EAAQ,GAAOC,EAAc,KACpCC,EAAQjB,EAAM,MAAOiB,EAAOA,EAAQA,EAAM,KACjD,GAAIA,EAAM,OAAS,UAAYA,EAAM,MAAQ,IAAK,CAChDH,EAASG,EAAM,OAASlB,EAAO,WAC/B,KACF,CAEEc,IAAS,UACXE,EAAQ,KACRC,EAAcjB,EAAO,OAAO,EAAIA,EAAO,QAAQ,EAAE,QACxCC,EAAM,MAAM,QACrBA,EAAM,MAAM,MAAQ,IAEtBA,EAAM,MAAQ,CACZ,OAAQc,EACR,KAAMD,EACN,KAAMb,EAAM,MACZ,MAAOe,EACP,YAAaC,CACf,CACF,CAEA,SAASb,EAAOJ,EAAQC,EAAO,CAC7B,GAAKA,EAAM,MAAM,KACjB,GAAIA,EAAM,MAAM,OAAS,SAAU,CAGjC,QAFIkB,EAAUnB,EAAO,YAAY,EAC7BoB,EAAU,GACLF,EAAQjB,EAAM,MAAOiB,EAAOA,EAAQA,EAAM,KACjD,GAAIC,IAAYD,EAAM,OAAQ,CAC5BE,EAAU,GACV,KACF,CAEF,GAAI,CAACA,EACH,MAAO,GAET,KAAOnB,EAAM,MAAM,MAAQA,EAAM,MAAM,SAAWkB,GAChDlB,EAAM,MAAQA,EAAM,MAAM,KAE5B,MAAO,EACT,KACE,QAAAA,EAAM,MAAQA,EAAM,MAAM,KACnB,EAEX,CAEA,SAASoB,EAAWrB,EAAQC,EAAO,CACjC,IAAIqB,EAAQrB,EAAM,SAASD,EAAQC,CAAK,EACpCsB,EAAUvB,EAAO,QAAQ,EAGzBuB,IAAY,WACdtB,EAAM,OAAS,MAEXsB,IAAY,MAAQA,IAAY,OAASvB,EAAO,IAAI,GACnDsB,IAAU,WACfT,EAAOb,EAAQC,CAAK,EAEtB,IAAIuB,EAAkB,MAAM,QAAQD,CAAO,EAY3C,GAXIC,IAAoB,IACtBX,EAAOb,EAAQC,EAAO,MAAM,MAAMuB,EAAiBA,EAAgB,CAAC,CAAC,EAEnEhC,EAAe,KAAK+B,CAAO,GAC7BV,EAAOb,EAAQC,CAAK,EAElBsB,GAAW,QACbnB,EAAOJ,EAAQC,CAAK,EAIlBqB,IAAU,UACRlB,EAAOJ,EAAQC,CAAK,EACtB,OAAOjB,EAIX,GADAwC,EAAkB,MAAM,QAAQD,CAAO,EACnCC,IAAoB,GAAI,CAC1B,KAAOvB,EAAM,MAAM,MAAQ,UAAYA,EAAM,MAAM,MACjDA,EAAM,MAAQA,EAAM,MAAM,KACxBA,EAAM,MAAM,MAAQsB,IACtBtB,EAAM,MAAQA,EAAM,MAAM,KAC9B,CACA,OAAIA,EAAM,QAAUD,EAAO,IAAI,IACzBC,EAAM,MAAM,MAAQ,UAAYA,EAAM,MAAM,OAC9CA,EAAM,MAAQA,EAAM,MAAM,MAC5BA,EAAM,OAAS,IAGVqB,GAAS,UAAYA,GAAS,SAAW,KAAOA,CACzD,CAEO,IAAMG,EAAe,CAC1B,KAAM,eACN,WAAY,UAAW,CACrB,MAAO,CACL,SAAU1B,EACV,MAAO,CAAC,OAAQ,EAAG,KAAK,SAAU,KAAM,KAAM,MAAO,EAAK,EAC1D,KAAM,GACN,OAAQ,CACV,CACF,EAEA,MAAO,SAASC,EAAQC,EAAO,CAC7B,IAAIyB,EAAYzB,EAAM,MAAM,QAAU,MAAQA,EAAM,MAChDyB,GAAa1B,EAAO,IAAI,IAAG0B,EAAU,MAAQ,IAEjD,IAAIJ,EAAQD,EAAWrB,EAAQC,CAAK,EACpC,OAAIqB,GAASA,GAAS,YAChBI,IAAWA,EAAU,MAAQ,IACjCzB,EAAM,KAAOqB,GAAS,eAAiBtB,EAAO,QAAQ,GAAK,KAGtDsB,CACT,EAEA,OAAQ,SAASrB,EAAO0B,EAAM,CAC5B,GAAI1B,EAAM,UAAYF,EAAW,MAAO,GACxC,IAAImB,EAAQjB,EAAM,MACd2B,EAASD,GAAQ,MAAM,QAAQA,EAAK,OAAO,CAAC,CAAC,EAAI,GACrD,GAAIC,EAAQ,KAAOV,EAAM,MAAQ,UAAYA,EAAM,MAAMA,EAAQA,EAAM,KACvE,IAAIW,EAASD,GAAUV,EAAM,OAASS,EAAK,OAAO,CAAC,EACnD,OAAIT,EAAM,MACDA,EAAM,aAAeW,EAAS,EAAI,IAEjCA,EAASX,EAAM,KAAOA,GAAO,MACzC,EAEA,aAAc,CACZ,cAAe,CAAC,KAAM,GAAG,CAC3B,CACF",
  "names": ["ERRORCLASS", "wordRegexp", "words", "operators", "delimiters", "identifiers", "atProp", "wordOperators", "indentKeywords", "commonKeywords", "keywords", "stringPrefixes", "regexPrefixes", "commonConstants", "constants", "tokenBase", "stream", "state", "scopeOffset", "lineOffset", "dedent", "ch", "longComment", "floatLiteral", "intLiteral", "tokenFactory", "delimiter", "singleline", "outclass", "indent", "type", "offset", "align", "alignOffset", "scope", "_indent", "matched", "tokenLexer", "style", "current", "delimiter_index", "coffeeScript", "fillAlign", "text", "closer", "closes"]
}
